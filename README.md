# TASK-5
In this task, we worked with a CSV dataset to explore decision trees and random forestsâ€”two popular machine learning methods. We started by loading and preparing the data, making sure the features and target labels were clearly separated and properly formatted. A decision tree classifier was then trained to understand how it makes predictions, and we visualized the tree to see its structure. To avoid overfitting (when a model memorizes rather than learns), we limited how deep the tree could grow. Next, we trained a random forest model, which combines many decision trees to make more accurate and stable predictions. We compared the performance of both models and found that the random forest generally gave better results. We also looked at which features were most important for the predictions. Finally, we used cross-validation to check how well our models would perform on unseen data. This hands-on process gave us a clear understanding of how tree-based models work and how to evaluate and improve them in practice.
